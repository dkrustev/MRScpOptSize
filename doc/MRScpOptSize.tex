\documentclass[submission,copyright,creativecommons]{eptcs}
\providecommand{\event}{VPT 2020} % Name of the event you are submitting to
\usepackage{breakurl}             % Not needed if you use pdflatex only.
\usepackage{underscore}           % Only needed if you use pdflatex.

\usepackage{listings}
\lstset{
  language=Caml,
  defaultdialect=[Objective]Caml,
  basicstyle=\scriptsize,
  frame=tb
  %	basicstyle=\small\ttfamily,
  %	commentstyle=\textit,
  %	keywordstyle=\bfseries
}

\usepackage{stmaryrd} % for \{ll,rr}bracket	

\title{Optimizing Program Size Using Multi-result Supercompilation}
\author{Dimitur Nikolaev Krustev
\institute{IGE+XAO Balkan\\ Sofia, Bulgaria}
\email{\quad dkrustev@ige-xao.com}
}
\def\titlerunning{Optimizing Program Size Using MRSC}
\def\authorrunning{D.N. Krustev}
\begin{document}
\maketitle

\begin{abstract}
This is a sentence in the abstract.
This is another sentence in the abstract.
This is yet another sentence in the abstract.
This is the final sentence in the abstract.
\end{abstract}

\section{Introduction}

Supercompilation was invented by Turchin \cite{TurchinSupercompilerConcept} and has found numerous
applications, such as program optimization\cite{XX,YY}, program verification \cite{Klyuchnikov},
$\ldots$.

Supercompilation performs very powerful program transformation by simulating
the actual execution of the input program on a whole set of possible inputs
simultaneously.
The flip side of this power is that the behavior of supercompilation -- 
with respect to both transformation time and result size --
can be very unpredictable.
This fact makes supercompilation problematic for including as an
optimization step of a standard compiler, for example.
Measures have been proposed to make supercompilation more
well-behaved, both in execution time and result size \cite{bolingbroke2011improving,Jonsson2011Taming}.
These proposals are all based on a combination of specially crafted and
empirically fine-tuned heuristics.
The main goal of the present study is to experiment with a more
principled approach to optimizing the size of the program resulting
from supercompilation.
This approach is based on a couple of key ideas:
\begin{itemize}
  \item use multi-result supercompilation\footnote{often abbreviated as \emph{MRSC} from now on} 
    to systematically explore a large set of different generalizations during 
    the transformation process, 
    leading to different trade-offs between performed optimizations and code explosion;
  \item carefully select a generalization scheme, which can avoid all forms of
    code duplication if applied systematically;
  \item re-use ideas from Grechanik et al. \cite{Romanenko2014StagedMRSC} to compactly represent and efficiently
    explore the set of programs resulting from multi-result supercompilation.
\end{itemize}
We outline the main ideas of multi-result supercompilation --
as well as the specific approach to its implementation that we use --
in Sec. \ref{sec:MRSCSummary}. We then describe the main contributions of this study:
\begin{itemize}
  \item We define a particular strategy for generalization during MRSC (Sec. \ref*{sec:Generalize}), which:
    \begin{itemize}
      \item avoids any risk of code duplication (when applied);
      \item avoids unnecessary increase of the search space of possible
        transformed programs, which MRSC must explore
    \end{itemize}
  \item We analyze the performance of the proposed strategy on several
    simple examples (Sec. \ref*{sec:EmpEval}).
\end{itemize}

\section{Summary of Multi-result Supercompilation}\label{sec:MRSCSummary}

Our implementation of multi-result supercompilation mostly follows the same
generic framework used in \cite{Romanenko2014StagedMRSC,Krustev2014MRSC}.
It offers some important simplifications compared by the original work
of Klyuchnikov et al. \cite{KlyuchnikovMRSCBranch,MRSCToolkit}:
\begin{itemize}
  \item It is based on big-step driving.
  \item All the set of transformed programs is represented compactly
    in a tree-like data structure, which further permits not only
    recovering the full set of configuration graphs, but also
    performing efficiently some kinds of queries on this set.
\end{itemize}
The compact representation of the set of graphs is shown in Fig. \ref{fig:GraphSet}.
We use direct excerpts of the F\# code of the implementation, but hopefully
they will be readable by anyone familiar with other functional languages such as OCaml and Haskell.
This representation is termed \emph{lazy graph} by Grechanik et al. \cite{Romanenko2014StagedMRSC},
and can be viewed as a domain-specific language (DSL) describing the construction of the
complete set of configuration graphs produced by multi-result supercompilation.
The semantics of this DSL is shown in the same Fig. \ref{fig:GraphSet} as
a function \lstinline|gset2graphs| expanding a \lstinline|GraphSet| into a sequence 
of configuration graphs.
Note the use of \lstinline|Seq.cartesian| to compose the sub-graphs of 
each graph node from the list of sub-graphs in the compact representation.

\begin{figure}
\begin{lstlisting}
type GraphSet =
  | GSNone
  | GSFold of MConf * int * list<VarName * VarName>
  | GSBuild of MConf * list<list<GraphSet>>

let rec gset2graphs (gs: GraphSet) : seq<MConf * ConfGraph> =
  match gs with
  | GSNone -> Seq.empty
  | GSFold(conf, n, ren) -> seq{ yield (conf, CGFold(n, ren)) }
  | GSBuild(conf, xss) ->
    xss
    |> Seq.collect (fun xs -> xs |> Seq.map gset2graphs |> Seq.cartesian)
    |> Seq.map (fun cgs -> (conf, buildGraph (snd conf) cgs))
\end{lstlisting}
\caption{Representation and Expansion of Graph Sets}
\label{fig:GraphSet}
\end{figure}

\section{Generalization Approach}\label{sec:Generalize}

\section{Empirical Evaluation}\label{sec:EmpEval}

\section{Future Work}

\section{Related Work}

\section{Conclusions}

%\nocite{*}
\bibliographystyle{eptcs}
\bibliography{MRScpOptSize}

\end{document}
